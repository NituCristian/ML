{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iteration1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCkBoscmT30G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, from_numpy, optim\n",
        "import numpy as np\n",
        "#pandas- librărie pentru lucrul cu fișierele\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUwR9ar9UGy0",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4dd87ae6-3c3b-4254-a1b6-b210c638e35c"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb5b6c4d-d715-4e46-a7d7-b7e0df29c78e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bb5b6c4d-d715-4e46-a7d7-b7e0df29c78e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pima-indians-diabetes.csv to pima-indians-diabetes (5).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTI49bnzUJVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['pima-indians-diabetes.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laXNeGdRUP9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "614e5a4c-83cc-4496-caf4-54d4c52c6395"
      },
      "source": [
        "df.values"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00e+00, 8.50e+01, 6.60e+01, ..., 3.51e-01, 3.10e+01, 0.00e+00],\n",
              "       [8.00e+00, 1.83e+02, 6.40e+01, ..., 6.72e-01, 3.20e+01, 1.00e+00],\n",
              "       [1.00e+00, 8.90e+01, 6.60e+01, ..., 1.67e-01, 2.10e+01, 0.00e+00],\n",
              "       ...,\n",
              "       [5.00e+00, 1.21e+02, 7.20e+01, ..., 2.45e-01, 3.00e+01, 0.00e+00],\n",
              "       [1.00e+00, 1.26e+02, 6.00e+01, ..., 3.49e-01, 4.70e+01, 1.00e+00],\n",
              "       [1.00e+00, 9.30e+01, 7.00e+01, ..., 3.15e-01, 2.30e+01, 0.00e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLH0O77TUmpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset - o clasă din PyTorch foarte utilă gestionării seturilor de date\n",
        "class PimaDiabetesDataset(Dataset):\n",
        "  # Initialize your data, download, etc.\n",
        "  def __init__(self):\n",
        "    #Citim setul de date\n",
        "    df = pd.read_csv(io.BytesIO(uploaded['pima-indians-diabetes.csv']), header=None, dtype=np.float32)\n",
        "    xy = torch.from_numpy(df.values)\n",
        "    self.len = xy.shape[0]\n",
        "    #Vom folosi ca input toate valorile mai puțin ultima coloană\n",
        "    self.x_data = xy[:, 0:-1]\n",
        "    #Vom folosi ca output ultima coloană\n",
        "    self.y_data = xy[:, [-1]]\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "     return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1wlbLItU31h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = PimaDiabetesDataset()\n",
        "#DataLoader - un utilitar ce ne ajută să împărțim setul de date pe batch-uri și astfel să facem antrenare în mod Mini-Batch\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1strXeEaR-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3007748a-fa19-44be-abd6-b0f89d2d129e"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  6.0000, 148.0000,  72.0000,  35.0000,   0.0000,  33.6000,   0.6270,\n",
              "          50.0000]), tensor([1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absNSTrdaZWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    #In the constructor we instantiate two nn.Linear module\n",
        "    super(Model, self).__init__()\n",
        "    self.l1 = nn.Linear(8, 6)\n",
        "    self.l2 = nn.Linear(6, 4)\n",
        "    self.l3 = nn.Linear(4, 1)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.ReLU = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # In the forward function we accept a Variable of input data and we must return\n",
        "    # a Variable of output data. We can use Modules defined in the constructor as\n",
        "    # well as arbitrary operators on Variables.\n",
        "    out1 = self.ReLU(self.l1(x))\n",
        "    out2 = self.ReLU(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pqSc9Rqangc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qu_qY5Cazik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RexSuXBa3KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b54cfeb6-30ff-4042-d518-c165ba21edf4"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(200):\n",
        "  # Aplicăm modificarea de learning rate per epocă, deci va trebui să avem un istoric al loss-ului\n",
        "  losses=[]\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(inputs)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, labels)\n",
        "    print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {loss.item():.4f}')\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    mean_loss=sum(losses)/len(losses)\n",
        "    scheduler.step(mean_loss)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 16 | Batch: 310 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 311 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 312 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 313 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 314 | Loss: 77.6197\n",
            "Epoch 16 | Batch: 315 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 316 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 317 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 318 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 319 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 320 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 321 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 322 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 323 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 324 | Loss: 72.8255\n",
            "Epoch 16 | Batch: 325 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 326 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 327 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 328 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 329 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 330 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 331 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 332 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 333 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 334 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 335 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 336 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 337 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 338 | Loss: 77.6331\n",
            "Epoch 16 | Batch: 339 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 340 | Loss: 79.3496\n",
            "Epoch 16 | Batch: 341 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 342 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 343 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 344 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 345 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 346 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 347 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 348 | Loss: 78.8666\n",
            "Epoch 16 | Batch: 349 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 350 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 351 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 352 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 353 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 354 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 355 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 356 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 357 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 358 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 359 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 360 | Loss: 81.0614\n",
            "Epoch 16 | Batch: 361 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 362 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 363 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 364 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 365 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 366 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 367 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 368 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 369 | Loss: 75.7973\n",
            "Epoch 16 | Batch: 370 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 371 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 372 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 373 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 374 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 375 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 376 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 377 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 378 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 379 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 380 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 381 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 382 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 383 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 384 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 385 | Loss: 78.6914\n",
            "Epoch 16 | Batch: 386 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 387 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 388 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 389 | Loss: 81.2028\n",
            "Epoch 16 | Batch: 390 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 391 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 392 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 393 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 394 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 395 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 396 | Loss: 80.2846\n",
            "Epoch 16 | Batch: 397 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 398 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 399 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 400 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 401 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 402 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 403 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 404 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 405 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 406 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 407 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 408 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 409 | Loss: 81.6418\n",
            "Epoch 16 | Batch: 410 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 411 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 412 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 413 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 414 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 415 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 416 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 417 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 418 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 419 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 420 | Loss: 84.5831\n",
            "Epoch 16 | Batch: 421 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 422 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 423 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 424 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 425 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 426 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 427 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 428 | Loss: 86.5084\n",
            "Epoch 16 | Batch: 429 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 430 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 431 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 432 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 433 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 434 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 435 | Loss: 73.4819\n",
            "Epoch 16 | Batch: 436 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 437 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 438 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 439 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 440 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 441 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 442 | Loss: 83.5017\n",
            "Epoch 16 | Batch: 443 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 444 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 445 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 446 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 447 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 448 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 449 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 450 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 451 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 452 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 453 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 454 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 455 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 456 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 457 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 458 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 459 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 460 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 461 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 462 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 463 | Loss: 37.9015\n",
            "Epoch 16 | Batch: 464 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 465 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 466 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 467 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 468 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 469 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 470 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 471 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 472 | Loss: 82.0811\n",
            "Epoch 16 | Batch: 473 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 474 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 475 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 476 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 477 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 478 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 479 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 480 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 481 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 482 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 483 | Loss: 78.9947\n",
            "Epoch 16 | Batch: 484 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 485 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 486 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 487 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 488 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 489 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 490 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 491 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 492 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 493 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 494 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 495 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 496 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 497 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 498 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 499 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 500 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 501 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 502 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 503 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 504 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 505 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 506 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 507 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 508 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 509 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 510 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 511 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 512 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 513 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 514 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 515 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 516 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 517 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 518 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 519 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 520 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 521 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 522 | Loss: 74.4825\n",
            "Epoch 16 | Batch: 523 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 524 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 525 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 526 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 527 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 528 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 529 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 530 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 531 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 532 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 533 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 534 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 535 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 536 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 537 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 538 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 539 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 540 | Loss: 86.9665\n",
            "Epoch 16 | Batch: 541 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 542 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 543 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 544 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 545 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 546 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 547 | Loss: 57.1509\n",
            "Epoch 16 | Batch: 548 | Loss: 83.5197\n",
            "Epoch 16 | Batch: 549 | Loss: 83.9617\n",
            "Epoch 16 | Batch: 550 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 551 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 552 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 553 | Loss: 72.1863\n",
            "Epoch 16 | Batch: 554 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 555 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 556 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 557 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 558 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 559 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 560 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 561 | Loss: 70.8544\n",
            "Epoch 16 | Batch: 562 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 563 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 564 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 565 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 566 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 567 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 568 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 569 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 570 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 571 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 572 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 573 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 574 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 575 | Loss: 78.0341\n",
            "Epoch 16 | Batch: 576 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 577 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 578 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 579 | Loss: 88.6027\n",
            "Epoch 16 | Batch: 580 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 581 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 582 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 583 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 584 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 585 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 586 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 587 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 588 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 589 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 590 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 591 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 592 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 593 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 594 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 595 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 596 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 597 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 598 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 599 | Loss: 71.2543\n",
            "Epoch 16 | Batch: 600 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 601 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 602 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 603 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 604 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 605 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 606 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 607 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 608 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 609 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 610 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 611 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 612 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 613 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 614 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 615 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 616 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 617 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 618 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 619 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 620 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 621 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 622 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 623 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 624 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 625 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 626 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 627 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 628 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 629 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 630 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 631 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 632 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 633 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 634 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 635 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 636 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 637 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 638 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 639 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 640 | Loss: 73.6809\n",
            "Epoch 16 | Batch: 641 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 642 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 643 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 644 | Loss: 72.8526\n",
            "Epoch 16 | Batch: 645 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 646 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 647 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 648 | Loss: 63.1172\n",
            "Epoch 16 | Batch: 649 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 650 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 651 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 652 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 653 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 654 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 655 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 656 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 657 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 658 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 659 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 660 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 661 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 662 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 663 | Loss: 88.3407\n",
            "Epoch 16 | Batch: 664 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 665 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 666 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 667 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 668 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 669 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 670 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 671 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 672 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 673 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 674 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 675 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 676 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 677 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 678 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 679 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 680 | Loss: 82.3361\n",
            "Epoch 16 | Batch: 681 | Loss: 79.9416\n",
            "Epoch 16 | Batch: 682 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 683 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 684 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 685 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 686 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 687 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 688 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 689 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 690 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 691 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 692 | Loss: 85.7553\n",
            "Epoch 16 | Batch: 693 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 694 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 695 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 696 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 697 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 698 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 699 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 700 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 701 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 702 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 703 | Loss: 85.2039\n",
            "Epoch 16 | Batch: 704 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 705 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 706 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 707 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 708 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 709 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 710 | Loss: 73.6036\n",
            "Epoch 16 | Batch: 711 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 712 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 713 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 714 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 715 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 716 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 717 | Loss: 61.7756\n",
            "Epoch 16 | Batch: 718 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 719 | Loss: 83.3961\n",
            "Epoch 16 | Batch: 720 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 721 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 722 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 723 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 724 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 725 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 726 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 727 | Loss: 77.4740\n",
            "Epoch 16 | Batch: 728 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 729 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 730 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 731 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 732 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 733 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 734 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 735 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 736 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 737 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 738 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 739 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 740 | Loss: 75.9038\n",
            "Epoch 16 | Batch: 741 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 742 | Loss: 85.6449\n",
            "Epoch 16 | Batch: 743 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 744 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 745 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 746 | Loss: 72.1991\n",
            "Epoch 16 | Batch: 747 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 748 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 749 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 750 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 751 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 752 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 753 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 754 | Loss: 88.4181\n",
            "Epoch 16 | Batch: 755 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 756 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 757 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 758 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 759 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 760 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 761 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 762 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 763 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 764 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 765 | Loss: 100.0000\n",
            "Epoch 16 | Batch: 766 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 767 | Loss: 0.0000\n",
            "Epoch 16 | Batch: 768 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 1 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 2 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 3 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 4 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 5 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 6 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 7 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 8 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 9 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 10 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 11 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 12 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 13 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 14 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 15 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 16 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 17 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 18 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 19 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 20 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 21 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 22 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 23 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 24 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 25 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 26 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 27 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 28 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 29 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 30 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 31 | Loss: 77.6331\n",
            "Epoch 17 | Batch: 32 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 33 | Loss: 86.5732\n",
            "Epoch 17 | Batch: 34 | Loss: 85.7553\n",
            "Epoch 17 | Batch: 35 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 36 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 37 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 38 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 39 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 40 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 41 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 42 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 43 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 44 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 45 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 46 | Loss: 81.9490\n",
            "Epoch 17 | Batch: 47 | Loss: 72.1991\n",
            "Epoch 17 | Batch: 48 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 49 | Loss: 88.3407\n",
            "Epoch 17 | Batch: 50 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 51 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 52 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 53 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 54 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 55 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 56 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 57 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 58 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 59 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 60 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 61 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 62 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 63 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 64 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 65 | Loss: 77.6197\n",
            "Epoch 17 | Batch: 66 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 67 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 68 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 69 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 70 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 71 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 72 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 73 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 74 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 75 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 76 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 77 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 78 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 79 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 80 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 81 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 82 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 83 | Loss: 74.4825\n",
            "Epoch 17 | Batch: 84 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 85 | Loss: 83.5197\n",
            "Epoch 17 | Batch: 86 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 87 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 88 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 89 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 90 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 91 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 92 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 93 | Loss: 84.6248\n",
            "Epoch 17 | Batch: 94 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 95 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 96 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 97 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 98 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 99 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 100 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 101 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 102 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 103 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 104 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 105 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 106 | Loss: 73.4819\n",
            "Epoch 17 | Batch: 107 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 108 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 109 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 110 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 111 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 112 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 113 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 114 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 115 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 116 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 117 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 118 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 119 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 120 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 121 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 122 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 123 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 124 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 125 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 126 | Loss: 79.7151\n",
            "Epoch 17 | Batch: 127 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 128 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 129 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 130 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 131 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 132 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 133 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 134 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 135 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 136 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 137 | Loss: 86.9665\n",
            "Epoch 17 | Batch: 138 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 139 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 140 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 141 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 142 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 143 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 144 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 145 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 146 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 147 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 148 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 149 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 150 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 151 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 152 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 153 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 154 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 155 | Loss: 77.4740\n",
            "Epoch 17 | Batch: 156 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 157 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 158 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 159 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 160 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 161 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 162 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 163 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 164 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 165 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 166 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 167 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 168 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 169 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 170 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 171 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 172 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 173 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 174 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 175 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 176 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 177 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 178 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 179 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 180 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 181 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 182 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 183 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 184 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 185 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 186 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 187 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 188 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 189 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 190 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 191 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 192 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 193 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 194 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 195 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 196 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 197 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 198 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 199 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 200 | Loss: 71.2543\n",
            "Epoch 17 | Batch: 201 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 202 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 203 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 204 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 205 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 206 | Loss: 85.6449\n",
            "Epoch 17 | Batch: 207 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 208 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 209 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 210 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 211 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 212 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 213 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 214 | Loss: 81.6418\n",
            "Epoch 17 | Batch: 215 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 216 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 217 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 218 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 219 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 220 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 221 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 222 | Loss: 37.9015\n",
            "Epoch 17 | Batch: 223 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 224 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 225 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 226 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 227 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 228 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 229 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 230 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 231 | Loss: 83.3961\n",
            "Epoch 17 | Batch: 232 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 233 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 234 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 235 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 236 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 237 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 238 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 239 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 240 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 241 | Loss: 81.7817\n",
            "Epoch 17 | Batch: 242 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 243 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 244 | Loss: 84.5831\n",
            "Epoch 17 | Batch: 245 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 246 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 247 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 248 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 249 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 250 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 251 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 252 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 253 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 254 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 255 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 256 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 257 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 258 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 259 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 260 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 261 | Loss: 68.8766\n",
            "Epoch 17 | Batch: 262 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 263 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 264 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 265 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 266 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 267 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 268 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 269 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 270 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 271 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 272 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 273 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 274 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 275 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 276 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 277 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 278 | Loss: 83.9617\n",
            "Epoch 17 | Batch: 279 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 280 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 281 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 282 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 283 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 284 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 285 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 286 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 287 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 288 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 289 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 290 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 291 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 292 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 293 | Loss: 81.3779\n",
            "Epoch 17 | Batch: 294 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 295 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 296 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 297 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 298 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 299 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 300 | Loss: 83.5017\n",
            "Epoch 17 | Batch: 301 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 302 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 303 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 304 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 305 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 306 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 307 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 308 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 309 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 310 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 311 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 312 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 313 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 314 | Loss: 68.8943\n",
            "Epoch 17 | Batch: 315 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 316 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 317 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 318 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 319 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 320 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 321 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 322 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 323 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 324 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 325 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 326 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 327 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 328 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 329 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 330 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 331 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 332 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 333 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 334 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 335 | Loss: 88.4181\n",
            "Epoch 17 | Batch: 336 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 337 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 338 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 339 | Loss: 67.8658\n",
            "Epoch 17 | Batch: 340 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 341 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 342 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 343 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 344 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 345 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 346 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 347 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 348 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 349 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 350 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 351 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 352 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 353 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 354 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 355 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 356 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 357 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 358 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 359 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 360 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 361 | Loss: 82.0811\n",
            "Epoch 17 | Batch: 362 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 363 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 364 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 365 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 366 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 367 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 368 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 369 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 370 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 371 | Loss: 72.8526\n",
            "Epoch 17 | Batch: 372 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 373 | Loss: 80.2846\n",
            "Epoch 17 | Batch: 374 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 375 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 376 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 377 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 378 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 379 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 380 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 381 | Loss: 72.8255\n",
            "Epoch 17 | Batch: 382 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 383 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 384 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 385 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 386 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 387 | Loss: 61.7756\n",
            "Epoch 17 | Batch: 388 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 389 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 390 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 391 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 392 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 393 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 394 | Loss: 63.1172\n",
            "Epoch 17 | Batch: 395 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 396 | Loss: 72.1863\n",
            "Epoch 17 | Batch: 397 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 398 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 399 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 400 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 401 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 402 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 403 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 404 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 405 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 406 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 407 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 408 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 409 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 410 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 411 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 412 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 413 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 414 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 415 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 416 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 417 | Loss: 81.0614\n",
            "Epoch 17 | Batch: 418 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 419 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 420 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 421 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 422 | Loss: 79.3496\n",
            "Epoch 17 | Batch: 423 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 424 | Loss: 73.6036\n",
            "Epoch 17 | Batch: 425 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 426 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 427 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 428 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 429 | Loss: 87.4356\n",
            "Epoch 17 | Batch: 430 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 431 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 432 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 433 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 434 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 435 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 436 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 437 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 438 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 439 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 440 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 441 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 442 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 443 | Loss: 85.1280\n",
            "Epoch 17 | Batch: 444 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 445 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 446 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 447 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 448 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 449 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 450 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 451 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 452 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 453 | Loss: 57.1509\n",
            "Epoch 17 | Batch: 454 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 455 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 456 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 457 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 458 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 459 | Loss: 86.5084\n",
            "Epoch 17 | Batch: 460 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 461 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 462 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 463 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 464 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 465 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 466 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 467 | Loss: 85.5565\n",
            "Epoch 17 | Batch: 468 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 469 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 470 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 471 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 472 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 473 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 474 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 475 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 476 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 477 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 478 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 479 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 480 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 481 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 482 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 483 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 484 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 485 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 486 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 487 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 488 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 489 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 490 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 491 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 492 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 493 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 494 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 495 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 496 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 497 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 498 | Loss: 53.1706\n",
            "Epoch 17 | Batch: 499 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 500 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 501 | Loss: 78.8666\n",
            "Epoch 17 | Batch: 502 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 503 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 504 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 505 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 506 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 507 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 508 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 509 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 510 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 511 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 512 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 513 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 514 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 515 | Loss: 88.0913\n",
            "Epoch 17 | Batch: 516 | Loss: 75.7973\n",
            "Epoch 17 | Batch: 517 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 518 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 519 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 520 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 521 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 522 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 523 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 524 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 525 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 526 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 527 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 528 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 529 | Loss: 78.0341\n",
            "Epoch 17 | Batch: 530 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 531 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 532 | Loss: 82.3857\n",
            "Epoch 17 | Batch: 533 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 534 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 535 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 536 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 537 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 538 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 539 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 540 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 541 | Loss: 40.5407\n",
            "Epoch 17 | Batch: 542 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 543 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 544 | Loss: 70.8544\n",
            "Epoch 17 | Batch: 545 | Loss: 85.2039\n",
            "Epoch 17 | Batch: 546 | Loss: 82.3159\n",
            "Epoch 17 | Batch: 547 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 548 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 549 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 550 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 551 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 552 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 553 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 554 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 555 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 556 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 557 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 558 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 559 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 560 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 561 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 562 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 563 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 564 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 565 | Loss: 78.9947\n",
            "Epoch 17 | Batch: 566 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 567 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 568 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 569 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 570 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 571 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 572 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 573 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 574 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 575 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 576 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 577 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 578 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 579 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 580 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 581 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 582 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 583 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 584 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 585 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 586 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 587 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 588 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 589 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 590 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 591 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 592 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 593 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 594 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 595 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 596 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 597 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 598 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 599 | Loss: 81.2028\n",
            "Epoch 17 | Batch: 600 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 601 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 602 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 603 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 604 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 605 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 606 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 607 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 608 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 609 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 610 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 611 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 612 | Loss: 73.6809\n",
            "Epoch 17 | Batch: 613 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 614 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 615 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 616 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 617 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 618 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 619 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 620 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 621 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 622 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 623 | Loss: 86.2567\n",
            "Epoch 17 | Batch: 624 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 625 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 626 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 627 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 628 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 629 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 630 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 631 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 632 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 633 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 634 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 635 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 636 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 637 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 638 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 639 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 640 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 641 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 642 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 643 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 644 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 645 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 646 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 647 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 648 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 649 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 650 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 651 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 652 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 653 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 654 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 655 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 656 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 657 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 658 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 659 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 660 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 661 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 662 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 663 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 664 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 665 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 666 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 667 | Loss: 78.6914\n",
            "Epoch 17 | Batch: 668 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 669 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 670 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 671 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 672 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 673 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 674 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 675 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 676 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 677 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 678 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 679 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 680 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 681 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 682 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 683 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 684 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 685 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 686 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 687 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 688 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 689 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 690 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 691 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 692 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 693 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 694 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 695 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 696 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 697 | Loss: 88.6027\n",
            "Epoch 17 | Batch: 698 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 699 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 700 | Loss: 79.2470\n",
            "Epoch 17 | Batch: 701 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 702 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 703 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 704 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 705 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 706 | Loss: 79.9416\n",
            "Epoch 17 | Batch: 707 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 708 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 709 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 710 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 711 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 712 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 713 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 714 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 715 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 716 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 717 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 718 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 719 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 720 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 721 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 722 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 723 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 724 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 725 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 726 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 727 | Loss: 82.3361\n",
            "Epoch 17 | Batch: 728 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 729 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 730 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 731 | Loss: 83.9877\n",
            "Epoch 17 | Batch: 732 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 733 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 734 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 735 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 736 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 737 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 738 | Loss: 84.4530\n",
            "Epoch 17 | Batch: 739 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 740 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 741 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 742 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 743 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 744 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 745 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 746 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 747 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 748 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 749 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 750 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 751 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 752 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 753 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 754 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 755 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 756 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 757 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 758 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 759 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 760 | Loss: 75.9038\n",
            "Epoch 17 | Batch: 761 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 762 | Loss: 100.0000\n",
            "Epoch 17 | Batch: 763 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 764 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 765 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 766 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 767 | Loss: 0.0000\n",
            "Epoch 17 | Batch: 768 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 1 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 2 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 3 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 4 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 5 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 6 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 7 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 8 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 9 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 10 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 11 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 12 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 13 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 14 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 15 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 16 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 17 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 18 | Loss: 0.0000\n",
            "Epoch 18 | Batch: 19 | Loss: 100.0000\n",
            "Epoch 18 | Batch: 20 | Loss: 100.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-257-defb2cdf7c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-_9zCDVa8K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}