# -*- coding: utf-8 -*-
"""Random_forest_loan_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kr_2X55J3ZixDpjAH39FRK1mIQUjFpvT
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import torch

loan=pd.read_csv("/content/loan_data_set.csv")

loan.head()

for n,v in loan.items():
    if v.dtype == "object":
        loan[n] = v.factorize()[0]

# Fill missing values with mean column values in the train set
loan.fillna(loan.mean(), inplace=True)

Cols = ['Loan_ID',	'Married', 'Gender',	'Dependents',	'Education',	'Self_Employed',	'ApplicantIncome',	'CoapplicantIncome',	'LoanAmount',	'Loan_Amount_Term',	'Credit_History',	'Property_Area']
X_cols = loan[Cols] # Features
Y_cols = loan.Loan_Status

# Import train_test_split function
from sklearn.model_selection import train_test_split

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X_cols, Y_cols, test_size=0.25) # 75% training and 25% test



from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score, classification_report
from sklearn.model_selection import train_test_split

random_forest = RandomForestClassifier(n_estimators=750).fit(X_train, y_train)
y_pred = random_forest.predict(X_test)
print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))
print('Recall score: ' + str(recall_score(y_test, y_pred)))
from sklearn.metrics import f1_score

f1 = f1_score(y_test, y_pred)

print('F1 score: %f' % f1)
print(classification_report(y_test, y_pred))

# Import the resampling package
from sklearn.utils import resample
# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_cols, Y_cols, test_size = 0.25)



# Returning to one dataframe
training_set = pd.concat([X_train, y_train], axis=1)
# Separating classes
test_loan = training_set[training_set.Loan_Status == 1]
not_test_loan = training_set[training_set.Loan_Status == 0]



# Undersampling the majority
undersample = resample(not_test_loan, 
                       replace=True, 
                       n_samples=len(test_loan), #set the number of samples to equal the number of the minority class
                       random_state=42)
# Returning to new training set
undersample_train = pd.concat([test_loan, undersample])
undersample_train.Loan_Status.value_counts(normalize=True)

# Separate undersampled data into X and y sets
undersample_x_train = undersample_train.drop('Loan_Status', axis=1)
undersample_y_train = undersample_train.Loan_Status
# Fit model on undersampled data
undersample_rf = RandomForestClassifier(n_estimators=750).fit(undersample_x_train, undersample_y_train)
# Make predictions on test sets
y_pred = random_forest.predict(X_test)
print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))
print('Average Recall score: ' + str(recall_score(y_test, y_pred, average='macro')))

f1 = f1_score(y_test, y_pred)

print('F1 score: %f' % f1)
print(classification_report(y_test, y_pred))





Cols = ['Loan_ID',	'Married',	'Dependents',	'Education',	'Self_Employed',	'ApplicantIncome',	'CoapplicantIncome',	'LoanAmount',	'Loan_Amount_Term',	'Credit_History',	'Property_Area', 'Loan_Status']
X_cols = loan[Cols] # Features
Y_cols = loan.Gender

X_train, X_test, y_train, y_test = train_test_split(X_cols, Y_cols, test_size = 0.25)

random_forest = RandomForestClassifier(n_estimators=750).fit(X_train, y_train)
y_pred = random_forest.predict(X_test)
print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))
print('Recall score: ' + str(recall_score(y_test, y_pred, average = 'macro')))
from sklearn.metrics import f1_score
f1 = f1_score(y_test, y_pred, average = 'macro')

print('F1 score: %f' % f1)
print(classification_report(y_test, y_pred))

X_train, X_test, y_train, y_test = train_test_split(X_cols, Y_cols, test_size = 0.25)

# Returning to one dataframe
training_set = pd.concat([X_train, y_train], axis=1)
# Separating classes
get_gender = training_set[training_set.Gender == 1]
not_get_gender = training_set[training_set.Gender == 0]

# Undersampling the majority
undersample = resample(not_get_gender, 
                       replace=True, 
                       n_samples=len(get_gender), #set the number of samples to equal the number of the minority class
                       random_state=42)
# Returning to new training set
undersample_train = pd.concat([get_gender, undersample])
undersample_train.Gender.value_counts(normalize=True)

# Separate undersampled data into X and y sets
undersample_x_train = undersample_train.drop('Gender', axis=1)

undersample_y_train = undersample_train.Gender
# Fit model on undersampled data
undersample_rf = RandomForestClassifier(n_estimators=750).fit(undersample_x_train, undersample_y_train)
# Make predictions on test sets
y_pred = random_forest.predict(X_test)
print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))
print('Average Recall score: ' + str(recall_score(y_test, y_pred, average='macro')))
from sklearn.metrics import f1_score
f1 = f1_score(y_test, y_pred, average = 'macro')

print('F1 score: %f' % f1)
print(classification_report(y_test, y_pred))

